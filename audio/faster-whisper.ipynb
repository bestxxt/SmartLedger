{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2f22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ! pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a3f27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "model_size = \"large-v3\"\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38da0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, info = model.transcribe(\"audio2.mp4\", beam_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1eeb507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'zh' with probability 0.987605\n"
     ]
    }
   ],
   "source": [
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "958e084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00s -> 2.00s] 翻译&字幕志愿者 杨茜茜. 父亲时钟\n",
      "[2.00s -> 4.00s] 作词 杨茜茜. 父亲时钟\n",
      "[4.00s -> 6.00s] 作曲 杨茜茜. 父亲时钟\n",
      "[12.00s -> 14.00s] 哈喽 大家好\n",
      "[14.00s -> 16.00s] 谢谢TED\n",
      "[16.00s -> 18.00s] 谢谢父亲时钟的邀请\n",
      "[18.00s -> 20.00s] 我是曾志晓女士\n",
      "[22.00s -> 24.00s] 好正式\n",
      "[24.00s -> 26.00s] 很可爱的主持人\n",
      "[26.00s -> 28.00s] 好 我非常荣幸\n",
      "[28.00s -> 30.00s] 可以跟大家分享\n",
      "[30.00s -> 32.00s] 我最近最有感的四个字\n",
      "[32.00s -> 34.00s] 突破框架\n",
      "[34.00s -> 36.00s] 首先我想要先跟大家聊聊\n",
      "[36.00s -> 38.00s] 确认一下大家对\n",
      "[38.00s -> 40.00s] 突破框架四个字\n",
      "[40.00s -> 42.00s] 是正面感受吗\n",
      "[42.00s -> 44.00s] 可以 有些人说是\n",
      "[44.00s -> 46.00s] 谢谢你理我 谢谢\n",
      "[46.00s -> 48.00s] 是是是\n",
      "[48.00s -> 50.00s] 好 那我们继续聊下去\n",
      "[50.00s -> 52.00s] 如果是正面感受的话\n",
      "[52.00s -> 54.00s] 我也是这样认同的\n",
      "[54.00s -> 56.00s] 我认为突破框架不是一个\n",
      "[56.00s -> 58.00s] 举动 或是一个做法\n",
      "[58.00s -> 60.00s] 我觉得更重要它是一个\n",
      "[60.00s -> 62.00s] 态度\n",
      "[62.00s -> 64.00s] 一种精神\n",
      "[64.00s -> 66.00s] 突破框架\n",
      "[66.00s -> 68.00s] 我是一个很喜欢拆解\n",
      "[68.00s -> 70.00s] 字面的人\n",
      "[70.00s -> 72.00s] 我想要先跟大家分享\n",
      "[72.00s -> 74.00s] 如果你认为\n",
      "[74.00s -> 76.00s] 我是一个突破框架的\n",
      "[76.00s -> 78.00s] 人\n",
      "[78.00s -> 80.00s] 或是你认为我是一个\n",
      "[80.00s -> 82.00s] 突破框架的女性\n",
      "[82.00s -> 84.00s] 突破框架的艺人\n",
      "[84.00s -> 86.00s] 那接下来\n",
      "[86.00s -> 88.00s] 我要邀请你认真的听我的分享\n",
      "[88.00s -> 90.00s] 但是\n",
      "[90.00s -> 92.00s] 不要相信我说的\n",
      "[92.00s -> 94.00s] 任何一句话\n",
      "[94.00s -> 96.00s] 有没有很吊诡\n",
      "[98.00s -> 100.00s] 我因为19岁的时候\n",
      "[100.00s -> 102.00s] 跌了对我人生蛮重要的一跤\n",
      "[102.00s -> 104.00s] 我得到轻度的忧郁症\n",
      "[104.00s -> 106.00s] 那是我非常珍贵的一个\n",
      "[106.00s -> 108.00s] 一段经历 因为那样子的一个\n",
      "[108.00s -> 110.00s] 挫败以及困惑\n",
      "[110.00s -> 112.00s] 带我很年轻走上了一个\n",
      "[112.00s -> 114.00s] 自我认识\n",
      "[114.00s -> 116.00s] 你可以称它为修行甚至是信仰的\n",
      "[116.00s -> 118.00s] 这一条路\n",
      "[118.00s -> 120.00s] 所以我花了非常多年的时间\n",
      "[120.00s -> 122.00s] 直到现在\n",
      "[122.00s -> 124.00s] 参与了很多心灵成长课程\n",
      "[124.00s -> 126.00s] 工作坊 飞到国外找大师\n",
      "[126.00s -> 128.00s] 看这样的书籍\n",
      "[128.00s -> 130.00s] 我走了很多各门各派的\n",
      "[130.00s -> 132.00s] 这样子的路\n",
      "[132.00s -> 134.00s] 每一次很多书籍或很多影片\n",
      "[134.00s -> 136.00s] 或是很多课程的开始\n",
      "[136.00s -> 138.00s] 大师们老师们这些剧作家们\n",
      "[138.00s -> 140.00s] 都很爱讲这一句话\n",
      "[140.00s -> 142.00s] 不要相信我说的\n",
      "[142.00s -> 144.00s] 任何一句话\n",
      "[144.00s -> 146.00s] 不要轻易的相信\n",
      "[146.00s -> 148.00s] 那如果你\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[\u001b[39;49m\u001b[38;5;132;43;01m%.2f\u001b[39;49;00m\u001b[38;5;124;43ms -> \u001b[39;49m\u001b[38;5;132;43;01m%.2f\u001b[39;49;00m\u001b[38;5;124;43ms] \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dp/lib/python3.11/site-packages/faster_whisper/transcribe.py:1148\u001b[0m, in \u001b[0;36mWhisperModel.generate_segments\u001b[0;34m(self, features, tokenizer, options, log_progress, encoder_output)\u001b[0m\n\u001b[1;32m   1145\u001b[0m previous_tokens \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seek \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m encoder_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1148\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mmultilingual:\n\u001b[1;32m   1151\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdetect_language(encoder_output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dp/lib/python3.11/site-packages/faster_whisper/transcribe.py:1358\u001b[0m, in \u001b[0;36mWhisperModel.encode\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(features, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1356\u001b[0m features \u001b[38;5;241m=\u001b[39m get_ctranslate2_storage(features)\n\u001b[0;32m-> 1358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_cpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_cpu\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efacc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "for segment in segments:\n",
    "    print(segment.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5898aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ! pip install fastapi\n",
    "_ = ! pip install uvicorn\n",
    "_ = ! pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d2494dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "import uvicorn\n",
    "import os\n",
    "import uuid\n",
    "import torch\n",
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0d462d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00af4604f2a04b2dbc85a88797a2b505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe99f44cfbe4594a189522a3a414661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21703ad2d854131a4eb11a95686a6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee66e011fcb544f89f6bf07dc8526a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/75.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Faster Whisper Transcription API\",\n",
    "    description=\"Upload an audio file and receive its transcription using faster-whisper.\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Load the Whisper model on startup\n",
    "MODEL_SIZE = \"tiny\"  # other sizes: tiny, base, medium, large\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "whisper_model = WhisperModel(\n",
    "    model_size_or_path=MODEL_SIZE,\n",
    "    device=DEVICE,\n",
    "    compute_type=\"int8\"  # quantized inference\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1025237",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FastAPI' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m             os\u001b[38;5;241m.\u001b[39mremove(temp_path)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m(app, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8000\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FastAPI' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "@app.post(\"/transcribe\")\n",
    "async def transcribe_audio(file: UploadFile = File(...)):\n",
    "    # Validate file type\n",
    "    if not file.content_type.startswith((\"audio/\", \"video/\")):\n",
    "        raise HTTPException(status_code=400, detail=\"Unsupported file type\")\n",
    "\n",
    "    # Save upload to temporary file\n",
    "    ext = file.filename.split('.')[-1]\n",
    "    temp_path = f\"/tmp/{uuid.uuid4()}.{ext}\"\n",
    "    contents = await file.read()\n",
    "    with open(temp_path, \"wb\") as f:\n",
    "        f.write(contents)\n",
    "\n",
    "    try:\n",
    "        # Perform transcription\n",
    "        segments, info = whisper_model.transcribe(\n",
    "            temp_path,\n",
    "            beam_size=5  # adjust for quality vs speed\n",
    "        )\n",
    "        # Concatenate segment texts\n",
    "        transcript = \"\".join([segment.text for segment in segments]).strip()\n",
    "        result = {\n",
    "            \"text\": transcript,\n",
    "            \"language\": info.language,\n",
    "            \"language_probability\": info.language_probability\n",
    "        }\n",
    "        return JSONResponse(content=result)\n",
    "    finally:\n",
    "        # Clean up temp file\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
